#!/usr/bin/env python

#PBS -l nodes=1:ppn=1
#PBS -l vmem=1gb
#PBS -l walltime=00:05:00
#PBS -N archive
##PBS -q normal
##PBS -A TG-DBS170009

import json
import subprocess
import errno
import os
import sys

with open("config.json") as config_json:
    config = json.load(config_json)
    product = {}
    for dataset in config["datasets"]:
        storage=dataset["storage"]
        dest=os.environ["BRAINLIFE_ARCHIVE_"+storage]+"/"+dataset["project"]
        try: 
            os.makedirs(dest)
        except OSError as exc:
            if exc.errno == errno.EEXIST and os.path.isdir(dest):
                pass
            else:
                raise

        tarname=dest+"/"+dataset["dataset"]["_id"]+".tar"
        cmd=["tar", "hcvf", tarname]
        files=[]

        if "files" in dataset and dataset["files"] != None:
            #old archive method used !
            #we need to re-stage everything (using dataset._id as staging dirname) so that we can handle file_override
            #let's use dataset id as staging dir inside input directory (bad?)
            stagedir = dataset["dir"]+"/"+dataset["dataset"]["_id"]

            files.append("-C")
            files.append(stagedir)

            #now we need to set symlink for all file/dir
            for file in dataset["files"]:
                if "filename" in file:
                    path = file["filename"]
                else:
                    path = file["dirname"]

                over_path = path
                if "files_override" in dataset and dataset["files_override"] != None:
                    print("looking.........")
                    if file["id"] in dataset["files_override"]:
                        over_path = dataset["files_override"][file["id"]]
                        print("file override", file["id"], over_path)

                if path == ".":
                    stagedir=dataset["dir"]
                    if over_path != ".":
                        stagedir += "/"+over_path
                    print("dot(.) path used.. using all local files as %s" % stagedir)
                    files = ["-C", stagedir]
                    files.extend(os.listdir(stagedir))
                    break         
      
                src_path = over_path
                link_path = stagedir
                if path != ".":
                    src_path = "../"+over_path
                    link_path = stagedir+"/"+path

                print("making sure stagedir exists", stagedir)
                #I only have to do this once, but I have to do it before I create the first symlink
                #I also don't know if I have over_path == "." until I start looping.. 
                #let's just check this for each file
                try: 
                    os.makedirs(stagedir)
                except OSError as exc:
                    if exc.errno == errno.EEXIST:
                        pass
                    else:
                        raise

                #if path == "." and over_path != ".":
                #    src_path = "../"+over_path
                #    link_path = stagedir+"/"+over_path

                print("making symlink src:", src_path, "dest:", link_path, "(dest is the link to create)")
                try: 
                    os.symlink(src_path, link_path)
                except OSError as exc:
                    if exc.errno == errno.EEXIST:
                        os.remove(link_path)
                        os.symlink(src_path, link_path)
                    else:
                        raise

                #some file/dir are not required
                if os.path.exists(dataset["dir"]+"/"+over_path):
                    files.append(path)
                elif file["required"] == True:
                    print("required file is missing:"+dataset["dir"]+"/"+path)
                    sys.exit(1)

            #dedupe the files
            files_dedupe = []
            for f in files:
              if f not in files_dedupe:
                files_dedupe.append(f)
            files = files_dedupe

            #store .brainlife.json
            #print("writing .brainlife.json at %s" % stagedir)
            #with open(stagedir+"/.brainlife.json", "w") as bljson:
            #    json.dump(dataset["dataset"], bljson)

        else:
            #new method is clean! just grab everything under "dir"
            files.append("-C")
            files.append(dataset["dir"])
            for file in os.listdir(dataset["dir"]):
                files.append(file)

            #store .brainlife.json
            #with open(dataset["dir"]+"/.brainlife.json", "w") as bljson:
            #    json.dump(dataset["dataset"], bljson)

        #files.append(".brainlife.json")

        #archive!
        cmd.extend(files)
        #print(cmd)
        subprocess.call(cmd)
        
        #print("archived to %s" % tarname)
        #print(subprocess.check_output(["tar","-tf",tarname]))

        #get file size 
        product[dataset["dataset"]["_id"]] = {"size":os.path.getsize(tarname)}

    with open('product.json', 'w') as productjson:
        json.dump(product, productjson)

    print("all done")
