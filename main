#!/bin/env python

#PBS -l nodes=1:ppn=1
#PBS -l vmem=1gb
#PBS -l walltime=00:05:00
#PBS -N archive
#PBS -q normal
#PBS -A TG-DBS170009

import json
import subprocess
import errno
import os
import sys

with open("config.json") as config_json:
    config = json.load(config_json)
    for dataset in config["datasets"]:
        dest=os.environ["BRAINLIFE_ARCHIVE"]+"/"+dataset["project"]
        try: 
            os.makedirs(dest)
        except OSError as exc:
            if exc.errno == errno.EEXIST and os.path.isdir(dest):
                pass
            else:
                raise

        #store .brainlife.json
        with open(dataset["dir"]+"/.brainlife.json", "w") as bljson:
            json.dump(dataset["dataset"], bljson)

        tarname=dest+"/"+dataset["dataset"]["_id"]+".tar"
        cmd=["tar", "hcvf", tarname, "-C", dataset["dir"]]

        if "files" in dataset and dataset["files"] != None:
            #old archiver had "files["dataset"]" listing all files to archive
            files=[".brainlife.json"]
            for file in dataset["files"]:
                if "filename" in file:
                    path = file["filename"]
                else:
                    path = file["dirname"]

                if "files_override" in dataset and dataset["files_override"] != None:
                    if file["id"] in dataset["files_override"]:
                        path = dataset["files_override"][file["id"]]

                if os.path.exists(dataset["dir"]+"/"+path):
                    cmd.append(path)
                elif file["required"] == True:
                    print("required file is missing:"+dataset["dir"]+"/"+path)
                    sys.exit(1)

        else:
            #grab everything under "dir"
            files=os.listdir(dataset["dir"])

        cmd.extend(files)
        print(cmd)
        subprocess.call(cmd)
