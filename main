#!/bin/env python

#PBS -l nodes=1:ppn=1
#PBS -l vmem=1gb
#PBS -l walltime=00:05:00
#PBS -N archive
#PBS -q normal
#PBS -A TG-DBS170009

import json
import subprocess
import errno
import os
import sys

with open("config.json") as config_json:
    config = json.load(config_json)
    for dataset in config["datasets"]:
        dest=os.environ["BRAINLIFE_ARCHIVE"]+"/"+dataset["project"]
        try: 
            os.makedirs(dest)
        except OSError as exc:
            if exc.errno == errno.EEXIST and os.path.isdir(dest):
                pass
            else:
                raise

        #store .brainlife.json
        with open(dataset["dir"]+"/.brainlife.json", "w") as bljson:
            json.dump(dataset["dataset"], bljson)

        tarname=dest+"/"+dataset["dataset"]["_id"]+".tar"
        cmd=["tar", "cvf", tarname, "-C", dataset["dir"]]

        if "files" in dataset:
            #old archiver had "files["dataset"]" listing all files to archive
            files=[]
            for file in dataset["files"]:
                if hasattr(file, "filename"):
                    path = file["filename"]
                else:
                    path = file["dirname"]

                if os.path.exists(dataset["dir"]+"/"+path):
                    cmd.append(path)
                elif file["required"] == True:
                    print("required file is missing:"+path)
                    sys.exit(1)

        else:
            #grab everything under "dir"
            files=os.listdir(dataset["dir"])

        cmd.extend(files)
        print(cmd)
        subprocess.call(cmd)
